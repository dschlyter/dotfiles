#!/usr/bin/env python3

# PRO TIP: PATH=... on top of crontab to make cron behave like your shell
# PRO TIP: a default config is stored in the scripts repository

import json
import os
import sys
import subprocess
import socket
import time
import argparse
from subprocess import Popen, PIPE
from pathlib import Path
from datetime import datetime, timedelta
from dateutil import parser

HOME = str(Path.home())
LOG_DIR = HOME+'/.logs/cron-run/'
CONF = HOME+'/.config/cron-run.json'
CONF_TIME = HOME+'/.config/cron-run-times.json'


def main():
    parser = argparse.ArgumentParser(description='Run user programs from cron, with logging, scheduling at most once per day/week and health callbacks.')
    parser.add_argument('command_args', nargs='+', help='the command to run')
    parser.add_argument('--name', dest='job_name', help='name of the job used for log file and healthcheck', required=True)
    parser.add_argument('--health-slo', dest='health_slo', type=int, help='report health with slo of N days, if omitted health will not be reported')
    parser.add_argument('--daily', dest='daily', action='store_const', const=True, help='run at most daily')
    parser.add_argument('--weekly', dest='weekly', action='store_const', const=True, help='run at most weekly')

    args = parser.parse_args()

    if args.daily or args.weekly:
        if not should_run(args.job_name, 7 if args.weekly else 1):
            print("Not time to run")
            return

    try:
        run_and_report(args)
    except Exception as ex:
        report_error(args.job_name, "cron-run internal error " + str(ex), Log())
        raise ex


def run_and_report(args):
    start = time.time()
    log = Log()
    log.append(datetime.now().isoformat())

    log.append(f"Running {args}")

    p = Popen(args.command_args, stdout=PIPE, stderr=subprocess.STDOUT, close_fds=True)

    # Stream output while running the command
    # Run this command with python -u to get snappy output
    stdout_b = b''
    while True:
        bytes = p.stdout.read(1)
        if not bytes:
            break
        stdout_b += bytes
        sys.stdout.buffer.write(bytes)
    p.stdout.close()
    code = p.wait()

    stdout_rows = stdout_b.decode('utf-8', errors='replace').splitlines()
    log.append_all(stdout_rows, output=False)
    log.append(f"job returned {code}")
    log.append(f"completed in {time.time() - start} seconds")

    log_to_disk(args.job_name, log)

    if code != 0:
        report_error(args.job_name, log.as_string(), log)

    if args.health_slo:
        report_status(args.job_name, "success" if code == 0 else "error", args.health_slo, log.log_data)
    else:
        log.append(f"Skipping health endpoint reporting")


def parse(argv):
    job_name = argv[1]
    next_run = 7

    cmd_start = 2
    if argv[2].isdigit():
        next_run = int(argv[2])
        cmd_start = 3

    cmd = argv[cmd_start:]
    return job_name, next_run, cmd


def log_to_disk(job_name, log):
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    log_file = "{}/{}.log".format(LOG_DIR, job_name)

    # crude log rotation. rotate on 1 MB log file. one old copy will be kept
    if os.path.exists(log_file) and os.path.getsize(log_file) > 1e6:
        os.replace(log_file, log_file + ".old")

    with open(log_file, encoding='utf-8', mode='a') as file:
        file.write("\n\n")
        file.write(log.as_string())


def report_error(job_name, error_msg, log):
    error_msg = error_msg[:1000]

    log.append("reporting error to slack")
    conf = load_conf(CONF, {})
    slack_url = conf.get('slack')
    if slack_url:
        json_data = json.dumps({
            'username': 'cron-run',
            'icon_emoji': ':ghost:',
            'text': '{} failed :/ Error: {}'.format(job_name, error_msg),
        })
        subprocess.check_call(['curl', '-X', 'POST', '--data-urlencode', 'payload='+json_data, slack_url])
        log.append("Error hook poked")
    else:
        log.append("Unable to load conf, cannot trigger error hook")


def report_status(job_name, status, next_run, logs):
    conf = load_conf(CONF, {})
    url = conf.get('healthcheck')
    if url:
        report_url = os.path.join(url, job_name)
        json_data = json.dumps({
            'status': status,
            'next': next_run,
            'host': socket.gethostname(),
            'log': logs,
        })
        p = Popen(['curl', '-X', 'POST', '-H', 'Content-Type: application/json', '--data', '@-', report_url], stdin=PIPE)
        p.communicate(input=json_data.encode('utf-8'))
        print("Healthcheck service informed")
    else:
        print("Unable to load conf, cannot update healthcheck")


def should_run(job_name, run_interval_days):
    now = datetime.now()
    conf = load_conf(CONF_TIME, dict())
    if job_name in conf:
        last_run_time = parser.parse(conf[job_name])
        if now < last_run_time + timedelta(days=run_interval_days):
            return False

    conf[job_name] = str(now)
    save_conf(conf, CONF_TIME)
    return True


def load_conf(path, default_value=None):
    try:
        with open(path, 'r') as data_file:
            return json.load(data_file)
    except (FileNotFoundError, json.JSONDecodeError):
        return default_value if default_value is not None else {}


def save_conf(data, path):
    with open(path, 'w') as data_file:
        json.dump(data, data_file)


class Log:
    def __init__(self):
        self.log_data = []

    def append(self, line, output=True):
        if output:
            print(line)
        self.log_data.append(line)

    def append_all(self, lines, output=True):
        for line in lines:
            self.append(line, output=output)

    def as_string(self):
        return "\n".join(self.log_data)


if __name__ == '__main__':
    main()
