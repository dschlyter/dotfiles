#!/usr/bin/env python3

# PRO TIP: PATH=... on top of crontab to make cron behave like your shell
# PRO TIP: a default config is stored in the scripts repository

import json
import os
import sys
import subprocess
import socket
import time
import argparse
from subprocess import Popen, PIPE
from pathlib import Path
from datetime import datetime, timedelta

HOME = str(Path.home())
LOG_DIR = HOME+'/.logs/cron-run/'
CONF = HOME+'/.config/cron-run.json'
CONF_TIME = HOME+'/.config/cron-run-times.json'


def main():
    parser = argparse.ArgumentParser(description='Run user programs from cron, with logging, scheduling at most once per day/week and health callbacks.')
    parser.add_argument('command_args', nargs='+', help='the command to run')
    parser.add_argument('--name', dest='job_name', help='name of the job used for log file and healthcheck', required=True)
    parser.add_argument('--health-slo', dest='health_slo', type=int, help='report health with slo of N days, if omitted health will not be reported')
    parser.add_argument('--daily', dest='daily', action='store_const', const=True, help='run at most daily')
    parser.add_argument('--weekly', dest='weekly', action='store_const', const=True, help='run at most weekly')

    args = parser.parse_args()

    if args.daily or args.weekly:
        if not (should_run(args.job_name, 7 if args.weekly else 1) or os.environ.get("FORCE_CRON_RUN", "0") == "1"):
            print("Not time to run - override with FORCE_CRON_RUN=1")
            return

    try:
        run_and_report(args)
    except Exception as ex:
        report_error(args.job_name, "cron-run internal error " + str(ex), Log())
        raise ex


def run_and_report(args):
    start = time.time()
    log = Log()
    log.append(datetime.now().isoformat())
    log.append(f"Running {args}")

    p = Popen(args.command_args, stdout=PIPE, stderr=subprocess.STDOUT, close_fds=True)

    # Stream output while running the command - keep at most 10k bytes in memory
    cyclic_buffer = []
    i = 0
    BUF_MAX = 10000
    line_start = 0
    write = True
    while True:
        byte_out = p.stdout.read(100)
        if not byte_out:
            break
        sys.stdout.buffer.write(byte_out)

        for c in byte_out:
            t = i % BUF_MAX
            if write:
                if len(cyclic_buffer) <= t:
                    cyclic_buffer.append(c)
                else:
                    cyclic_buffer[t] = c
                i += 1

            # parse row output but ignore rows with \r or escape sequences - roll back to line start and pause writes when encountered
            if c == ord('\n'):
                line_start = i
                write = True
            if (c == ord('\r') or c == ord('\x1b')):
                i = line_start
                write = False

    p.stdout.close()
    code = p.wait()

    # Decode buffer to UTF-8 before appending to log
    buf_start = (i + 1) % BUF_MAX if i >= BUF_MAX else 0
    cyclic_buffer = cyclic_buffer[buf_start:] + cyclic_buffer[:buf_start]
    decoded_buffer = bytes(cyclic_buffer).decode('utf-8', errors='replace')

    log.append_all(decoded_buffer.splitlines(), output=False)
    log.append(f"job returned {code}")
    log.append(f"completed in {time.time() - start} seconds")

    log_to_disk(args.job_name, log)

    if code != 0:
        report_error(args.job_name, log.as_string(), log)

    if args.health_slo:
        report_status(args.job_name, "success" if code == 0 else "error", args.health_slo, log.log_data)
    else:
        log.append(f"Skipping health endpoint reporting")


def parse(argv):
    job_name = argv[1]
    next_run = 7

    cmd_start = 2
    if argv[2].isdigit():
        next_run = int(argv[2])
        cmd_start = 3

    cmd = argv[cmd_start:]
    return job_name, next_run, cmd


def log_to_disk(job_name, log):
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

    log_file = "{}/{}.log".format(LOG_DIR, job_name)

    # crude log rotation. rotate on 1 MB log file. one old copy will be kept
    if os.path.exists(log_file) and os.path.getsize(log_file) > 1e6:
        os.replace(log_file, log_file + ".old")

    with open(log_file, encoding='utf-8', mode='a') as file:
        file.write("\n\n")
        file.write(log.as_string())


def report_error(job_name, error_msg, log):
    error_msg = error_msg[:1000]

    log.append("reporting error to slack")
    conf = load_conf(CONF, {})
    slack_url = conf.get('slack')
    if slack_url:
        json_data = json.dumps({
            'username': 'cron-run',
            'icon_emoji': ':ghost:',
            'text': '{} failed :/ Error: {}'.format(job_name, error_msg),
        })
        subprocess.check_call(['curl', '-X', 'POST', '--data-urlencode', 'payload='+json_data, slack_url])
        log.append("Error hook poked")
    else:
        log.append("Unable to load conf, cannot trigger error hook")


def report_status(job_name, status, next_run, logs):
    conf = load_conf(CONF, {})
    url = conf.get('healthcheck')
    if url:
        report_url = "/".join([url.rstrip("/"), job_name])
        json_data = json.dumps({
            'status': status,
            'next': next_run,
            'host': socket.gethostname(),
            'log': logs,
        })
        p = Popen(['curl', '-X', 'POST', '-H', 'Content-Type: application/json', '--data', '@-', report_url], stdin=PIPE)
        p.communicate(input=json_data.encode('utf-8'))
        print("Healthcheck service informed")
    else:
        print("Unable to load conf, cannot update healthcheck")


def should_run(job_name, run_interval_days):
    now = datetime.now()
    date_format = '%Y-%m-%d %H:%M:%S.%f'
    conf = load_conf(CONF_TIME, dict())
    if job_name in conf:
        last_run_time = datetime.strptime(conf[job_name], date_format)
        if now < last_run_time + timedelta(days=run_interval_days):
            return False

    conf[job_name] = now.strftime(date_format)
    save_conf(conf, CONF_TIME)
    return True


def load_conf(path, default_value=None):
    try:
        with open(path, 'r') as data_file:
            return json.load(data_file)
    except (FileNotFoundError, json.JSONDecodeError):
        return default_value if default_value is not None else {}


def save_conf(data, path):
    with open(path, 'w') as data_file:
        json.dump(data, data_file)


class Log:
    def __init__(self):
        self.log_data = []

    def append(self, line, output=True):
        if output:
            print(line)
        self.log_data.append(line)

    def append_all(self, lines, output=True):
        for line in lines:
            self.append(line, output=output)

    def as_string(self):
        return "\n".join(self.log_data)


if __name__ == '__main__':
    main()
